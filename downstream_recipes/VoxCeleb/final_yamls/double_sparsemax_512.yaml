# ################################
# Model: Speaker Verification Baseline using PLDA
# Authors: Nauman Dawalatabad & Mirco Ravanelli 2020
# ################################

seed: 1234
__set_seed: !apply:torch.manual_seed [!ref <seed>]

# Folders and train_log file
data_folder: /gpfsscratch/rech/nou/uzn19yk/all_data/voxceleb/  # use vox 0, vox2, or vox1+vox2 dataset
output_folder: results/voxceleb1/verif_verif_yamls/double_sparsemax_512.yaml
save_folder: !ref <output_folder>/save/
device: 'cuda:0'

embedding_param: verif_yamls/double_sparsemax_512.yaml
csv_folder: /gpfsscratch/rech/nou/uzn19yk/all_data/voxceleb/
# csv files
train_data: !ref <csv_folder>/train.csv
enrol_data: !ref <csv_folder>/enrol.csv
test_data: !ref <csv_folder>/test.csv

batch_size: 8
score_norm: 't-norm' # z-norm t-norm s-norm none
n_train_snts: 300000 # used for normalization stats
baseline: False
# Feature parameters
n_mels: 80
left_frames: 0
right_frames: 0
deltas: False
emb_dim: 512

# Dataloader options
train_dataloader_opts:
    batch_size: !ref <batch_size>

enrol_dataloader_opts:
    batch_size: !ref <batch_size>

test_dataloader_opts:
    batch_size: !ref <batch_size>

compute_plda: !new:speechbrain.processing.PLDA_LDA.PLDA
    rank_f: 100
    nb_iter: 10
    scaling_factor: 0.05

embedding_model: !new:recipes.VoxCeleb.selftrained.Verification
    hparams_file: !ref <embedding_param>
    norm_emb: True
    save_folder: !ref <save_folder>